{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be916fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   crs  nationalLocationCode       name sixteenCharacterName  \\\n",
      "0  ABE                381300       Aber                 ABER   \n",
      "1  ACY                380100  Abercynon            ABERCYNON   \n",
      "2  ABA                398200   Aberdare             ABERDARE   \n",
      "3  AVY                443500  Aberdovey            ABERDOVEY   \n",
      "4  ABH                444000   Abererch             ABERERCH   \n",
      "\n",
      "                                             address      long        lat  \\\n",
      "0  Aber station, Nantgarw Road, Aber, Caerphilly,... -3.229839  51.574961   \n",
      "1  Abercynon station, Station Road, Abercynon, Rh... -3.327001  51.644706   \n",
      "2  Aberdare station, Abernant Road, Aberdare, Mid... -3.443099  51.715057   \n",
      "3  Aberdovey station, Station Road, Aberdovey, Gw... -4.057081  52.543972   \n",
      "4  Abererch station, Abererch Sands Road, Aberech... -4.374196  52.898600   \n",
      "\n",
      "                                                 uri  \n",
      "0  https://www.nationalrail.co.uk/stations/ABE/de...  \n",
      "1  https://www.nationalrail.co.uk/stations/ACY/de...  \n",
      "2  https://www.nationalrail.co.uk/stations/ABA/de...  \n",
      "3  https://www.nationalrail.co.uk/stations/AVY/de...  \n",
      "4  https://www.nationalrail.co.uk/stations/ABH/de...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/mahdi/Knowledge-Graph/nr-stations-all.csv\", nrows=5, encoding=\"utf-8-sig\")\n",
    "print(df)  # reveals BOM as \\\\ufeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed036a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def normalize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Normalize headers: strip, lowercase, remove BOM\n",
    "    df.columns = (df.columns\n",
    "        .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "    )\n",
    "    # Map likely ID columns to 'id'\n",
    "    for c in [\"id\",\"station_id\",\"code\",\"crs\",\"tiploc\"]:\n",
    "        if c in df.columns:\n",
    "            if c != \"id\":\n",
    "                df = df.rename(columns={c: \"id\"})\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(f\"No ID column found in headers: {list(df.columns)}\")\n",
    "\n",
    "    # Clean ID values\n",
    "    df[\"id\"] = df[\"id\"].astype(str).str.replace(\"\\ufeff\", \"\", regex=False).str.strip()\n",
    "    df.loc[df[\"id\"].isin([\"\", \"nan\", \"None\"]), \"id\"] = pd.NA\n",
    "\n",
    "    # Ensure optional columns exist\n",
    "    for c in [\"name\",\"lat\",\"lon\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df\n",
    "\n",
    "# Example read (utf-8-sig auto-strips BOM)\n",
    "chunk = pd.read_csv(\"/home/mahdi/Knowledge-Graph/nr-stations-all.csv\",\n",
    "                    chunksize=10_000, encoding=\"utf-8-sig\")\n",
    "for df in chunk:\n",
    "    df = normalize(df)\n",
    "    rows = df.dropna(subset=[\"id\"]).to_dict(\"records\")\n",
    "    # ... send rows using the guarded Cypher above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525b8b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stations: 2,593\n"
     ]
    }
   ],
   "source": [
    "# pip install neo4j\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# --- 1) Connect ---\n",
    "URI  = \"bolt://localhost:7687\"          # or neo4j+s://<your-aura-endpoint>\n",
    "user = \"neo4j\"\n",
    "password= \"Mbg!234567\"\n",
    "AUTH = (user,password)            # <- change\n",
    "host = \"bolt://127.0.0.1:7687\"\n",
    "\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "\n",
    "# 'stations' is your Python list of dicts (the one you pasted)\n",
    "stations = rows  # <â€” paste your list here\n",
    "\n",
    "# --- 2) Constraints (safe to re-run) ---\n",
    "with driver.session() as s:\n",
    "    s.run(\"\"\"\n",
    "    CREATE CONSTRAINT station_crs_unique IF NOT EXISTS\n",
    "    FOR (s:Station) REQUIRE s.crs IS UNIQUE\n",
    "    \"\"\")\n",
    "\n",
    "# --- 3) Writer (guards null/blank IDs, casts types, maps `long`->`lon`) ---\n",
    "def write_stations(tx, rows):\n",
    "    tx.run(\"\"\"\n",
    "    UNWIND $rows AS row\n",
    "    WITH row\n",
    "    WHERE row.crs IS NOT NULL AND trim(toString(row.crs)) <> \"\"\n",
    "    MERGE (s:Station {crs: toString(row.crs)})\n",
    "    SET  s.nationalLocationCode  = toString(row.nationalLocationCode),\n",
    "         s.name                  = row.name,\n",
    "         s.sixteenCharacterName  = row.sixteenCharacterName,\n",
    "         s.address               = row.address,\n",
    "         s.uri                   = row.uri,\n",
    "         // keep your original 'long' if you want, but also store 'lon'\n",
    "         s.long                  = CASE WHEN row.long IS NULL THEN NULL ELSE toFloat(row.long) END,\n",
    "         s.lon                   = CASE WHEN row.long IS NULL THEN NULL ELSE toFloat(row.long) END,\n",
    "         s.lat                   = CASE WHEN row.lat  IS NULL THEN NULL ELSE toFloat(row.lat)  END\n",
    "    \"\"\", rows=rows)\n",
    "\n",
    "# --- 4) Batch the write (adjust batch size if needed) ---\n",
    "BATCH = 1000\n",
    "for i in range(0, len(stations), BATCH):\n",
    "    batch = stations[i:i+BATCH]\n",
    "    with driver.session() as s:\n",
    "        s.execute_write(write_stations, batch)\n",
    "\n",
    "# --- 5) Quick sanity check ---\n",
    "with driver.session() as s:\n",
    "    count = s.run(\"MATCH (s:Station) RETURN count(s) AS n\").single()[\"n\"]\n",
    "print(f\"Loaded stations: {count:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab535c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc90381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd35d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49270ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['crs', 'nationalLocationCode', 'name', 'sixteenCharacterName', 'address', 'long', 'lat', 'uri']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/mahdi/Knowledge-Graph/nr-stations-all.csv\", nrows=5, encoding=\"utf-8-sig\")\n",
    "print(\"Columns:\", [c.encode('unicode_escape').decode() for c in df.columns])  # reveals BOM as \\\\ufeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275e671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
